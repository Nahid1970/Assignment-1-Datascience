{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nahid1970/Assignment-1-Datascience/blob/main/Improved_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWXLCdDhfOK1"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxrXEwtVfnNr",
        "outputId": "d72497ec-f5a9-42fa-97a5-8fa40f51cea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thyMWK_3fxlI"
      },
      "outputs": [],
      "source": [
        "#locations setting for training and test datasets\n",
        "train_data='/content/drive/MyDrive/Activity/Images/0'\n",
        "test_data='/content/drive/MyDrive/Activity/Testing/0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNX5_QLuf4v8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "from glob import glob\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spoaBQoNrqwc"
      },
      "outputs": [],
      "source": [
        "output=[\"Baseball\",\"BasketBall\" ,\"Fighting\",\"Football playing\",\"Hospital\",\"Eatting\",\"Skating\",\"walking\",\"working\"]\n",
        "lebel=[]\n",
        "output_lebel=[0,1,2,3,4,5,6,7,8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS72whI1rsoy",
        "outputId": "95b30b89-e7ee-4eb1-c229-efe5ed4f1510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "(1697, 120, 120, 3)\n",
            "(1697, 9)\n"
          ]
        }
      ],
      "source": [
        "img_shape = (120, 120, 3)\n",
        "train_dir=\"Images\"\n",
        " \n",
        "Name = \"Model0\"\n",
        "df = []\n",
        "lebel = []\n",
        "rel_dirname = '/content/drive/MyDrive/Activity/Images'\n",
        "    \n",
        "for dirname in os.listdir(rel_dirname):\n",
        "        print(dirname)\n",
        "        for filename in glob(rel_dirname+'/'+dirname+'/*.png'):\n",
        "             #print(filename)\n",
        "             img = image.load_img((filename),target_size=img_shape)\n",
        "             img = image.img_to_array(img)\n",
        "             img = img/255.0\n",
        "             df.append(img)\n",
        "             lebel.append(dirname)\n",
        "X = np.array(df)\n",
        "lebel = np.array(lebel)\n",
        "y = to_categorical(lebel)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so2UD6jGr1dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a36f48-71a6-42ad-820a-cfee2ac7c059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1357, 120, 120, 3)\n",
            "(1357, 9)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTqjLgkHxWjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b259b13-d350-4273-d2f5-7db2448c11ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 120, 120, 16)      208       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 120, 120, 16)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 60, 60, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        2080      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 150)               940950    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 150)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 1359      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 985,749\n",
            "Trainable params: 985,749\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Building model 1 using customized convolutional and pooling layers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#input_shape is 100*100 since thats the dimension of each of the human images\n",
        "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(120,120,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "# specifying parameters for fully connected layer\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(9,activation = 'softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWHsd_tQr7Kh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hQgKCgr9LE"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7q_SvaivGRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d50cab9-9ba1-4ecb-8710-70e67f9b4574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "img_width, img_height = 120, 120\n",
        "base_model=ResNet50(weights='imagenet',include_top=False, input_shape=(img_width, img_height, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojbgjJaYvJDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458b736f-89dd-47e0-d76b-60698900fbd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  175\n"
          ]
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqixZlvRr_Fs"
      },
      "outputs": [],
      "source": [
        "fine_tune_at = 85\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcUBpy28sBH8"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztG2WruZvUhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82018a64-7319-4857-a565-087176fab8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 2313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,114,569\n",
            "Trainable params: 21,889,545\n",
            "Non-trainable params: 2,225,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#adding some layers to the resnet 50_model imported and again fitting the model to check the performance\n",
        "\n",
        "transfer_learning_model = Sequential()\n",
        " \n",
        "transfer_learning_model.add(base_model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transfer_learning_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "transfer_learning_model.add(Dense(256))\n",
        "transfer_learning_model.add(Activation('relu'))\n",
        "transfer_learning_model.add(Dropout(0.4))\n",
        "transfer_learning_model.add(Dense(9,activation = 'softmax'))\n",
        "transfer_learning_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAYUuMNFvZDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40578e6c-5175-40cc-9b10-608830ca3864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model,to_file=\"base_model.png\", show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8WQ1JB9vavI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c06fea3-1686-41a5-9fd2-5d084af07f55"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5857 - accuracy: 0.4923 - recall: 0.3545 - precision: 0.6756\n",
            "Epoch 00001: val_loss improved from inf to 18.33106, saving model to transfer_learning.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.0952e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5744/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1709e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05744: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1709e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5745/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4597e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05745: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4597e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5746/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4436e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05746: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.4436e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5747/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7496e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05747: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.7496e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5748/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.2283e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05748: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 6.2283e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5749/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7071e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05749: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.7071e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5750/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8111e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05750: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.8111e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5751/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2167e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05751: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.2167e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5752/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0820e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05752: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0820e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5753/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6734e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05753: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6734e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5754/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6975e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05754: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.6975e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5755/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5139e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05755: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 298ms/step - loss: 3.5139e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5756/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4419e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05756: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.4419e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5757/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3800e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05757: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3800e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5758/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3686e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05758: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.3686e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5759/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8957e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05759: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 6.8957e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5760/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6734e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05760: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.6734e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5761/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6559e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05761: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.6559e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5762/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4945e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05762: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.4945e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5763/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8065e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05763: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.8065e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5764/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3469e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05764: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 3.3469e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5765/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0293e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05765: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0293e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5766/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2504e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05766: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.2504e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5767/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6935e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05767: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.6935e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5768/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.2589e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05768: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.2589e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5769/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3192e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05769: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.3192e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5770/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1754e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05770: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1754e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5771/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0775e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05771: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.0775e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5772/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2914e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05772: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.2914e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5773/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6892e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05773: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.6892e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5774/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5327e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05774: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5327e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5775/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7921e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05775: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.7921e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5776/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5915e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05776: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.5915e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5777/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1054e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05777: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.1054e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5778/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2131e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05778: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2131e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5779/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8582e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05779: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.8582e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5780/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.9339e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05780: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 8.9339e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5781/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6614e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05781: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 2.6614e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5782/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1288e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05782: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.1288e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5783/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.5754e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05783: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 9.5754e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5784/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0262e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05784: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0262e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5785/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1829e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05785: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.1829e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5786/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1140e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05786: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.1140e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5787/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0747e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05787: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 3.0747e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5788/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7159e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05788: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.7159e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5789/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0542e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05789: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0542e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5790/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.1452e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05790: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 8.1452e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5791/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6896e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05791: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 3.6896e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5792/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7643e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05792: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.7643e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5793/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5057e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05793: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.5057e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5794/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6164e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05794: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6164e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5795/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8154e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05795: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 5.8154e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5796/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5212e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05796: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.5212e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5797/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4231e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05797: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4231e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5798/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0952e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05798: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.0952e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5799/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2913e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05799: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.2913e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5800/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4597e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05800: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4597e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5801/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4948e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05801: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.4948e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5802/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2421e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05802: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2421e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5803/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0848e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05803: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.0848e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5804/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7657e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05804: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.7657e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5805/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0322e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05805: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 4.0322e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5806/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2709e-10 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05806: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 5.2709e-10 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5807/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0454e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05807: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0454e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5808/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3864e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05808: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.3864e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5809/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4934e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05809: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.4934e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5810/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7482e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05810: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.7482e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5811/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0638e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05811: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0638e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5812/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7101e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05812: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.7101e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5813/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9165e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05813: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.9165e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5814/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0858e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05814: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0858e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5815/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0338e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05815: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0338e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5816/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4353e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05816: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4353e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5817/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2854e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05817: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.2854e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5818/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7831e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05818: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.7831e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5819/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2919e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05819: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.2919e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5820/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1748e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05820: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.1748e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5821/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4509e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05821: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.4509e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5822/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5904e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05822: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.5904e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5823/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2731e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05823: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.2731e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5824/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3398e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05824: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.3398e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5825/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1262e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05825: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.1262e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5441 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 5826/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1478e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05826: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1478e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.9294 - val_recall: 0.9294 - val_precision: 0.9322\n",
            "Epoch 5827/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05827: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0096 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 1.9332 - val_accuracy: 0.8676 - val_recall: 0.8676 - val_precision: 0.8676\n",
            "Epoch 5828/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05828: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0033 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 88.0167 - val_accuracy: 0.2853 - val_recall: 0.2853 - val_precision: 0.2853\n",
            "Epoch 5829/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9948 - recall: 0.9948 - precision: 0.9948\n",
            "Epoch 05829: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0471 - accuracy: 0.9948 - recall: 0.9948 - precision: 0.9948 - val_loss: 49.7900 - val_accuracy: 0.4441 - val_recall: 0.4441 - val_precision: 0.4454\n",
            "Epoch 5830/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9993    \n",
            "Epoch 05830: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0059 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9993 - val_loss: 61.0174 - val_accuracy: 0.4353 - val_recall: 0.4353 - val_precision: 0.4353\n",
            "Epoch 5831/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9956 - recall: 0.9956 - precision: 0.9956\n",
            "Epoch 05831: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0312 - accuracy: 0.9956 - recall: 0.9956 - precision: 0.9956 - val_loss: 72.2992 - val_accuracy: 0.4265 - val_recall: 0.4265 - val_precision: 0.4277\n",
            "Epoch 5832/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9956 - recall: 0.9956 - precision: 0.9956\n",
            "Epoch 05832: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0374 - accuracy: 0.9956 - recall: 0.9956 - precision: 0.9956 - val_loss: 40.4677 - val_accuracy: 0.5529 - val_recall: 0.5529 - val_precision: 0.5546\n",
            "Epoch 5833/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05833: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.0063 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 16.5145 - val_accuracy: 0.6882 - val_recall: 0.6882 - val_precision: 0.6882\n",
            "Epoch 5834/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05834: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 0.0127 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 105.9449 - val_accuracy: 0.3794 - val_recall: 0.3794 - val_precision: 0.3794\n",
            "Epoch 5835/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05835: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 266ms/step - loss: 0.0021 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 131.3403 - val_accuracy: 0.3382 - val_recall: 0.3382 - val_precision: 0.3382\n",
            "Epoch 5836/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2177e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05836: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2177e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 101.6117 - val_accuracy: 0.3912 - val_recall: 0.3912 - val_precision: 0.3912\n",
            "Epoch 5837/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3433e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05837: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.3433e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 69.6992 - val_accuracy: 0.4676 - val_recall: 0.4647 - val_precision: 0.4661\n",
            "Epoch 5838/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9945e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05838: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.9945e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 44.8108 - val_accuracy: 0.5647 - val_recall: 0.5647 - val_precision: 0.5647\n",
            "Epoch 5839/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2478e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05839: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 265ms/step - loss: 7.2478e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 28.6278 - val_accuracy: 0.6206 - val_recall: 0.6206 - val_precision: 0.6206\n",
            "Epoch 5840/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5660e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05840: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.5660e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 15.8007 - val_accuracy: 0.6941 - val_recall: 0.6941 - val_precision: 0.6941\n",
            "Epoch 5841/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3800e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05841: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.3800e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 8.6534 - val_accuracy: 0.7765 - val_recall: 0.7765 - val_precision: 0.7765\n",
            "Epoch 5842/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5499e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05842: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.5499e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 5.2608 - val_accuracy: 0.8529 - val_recall: 0.8529 - val_precision: 0.8529\n",
            "Epoch 5843/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4429e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05843: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4429e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.3226 - val_accuracy: 0.8824 - val_recall: 0.8824 - val_precision: 0.8824\n",
            "Epoch 5844/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8073e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05844: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.8073e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.1762 - val_accuracy: 0.9029 - val_recall: 0.9029 - val_precision: 0.9029\n",
            "Epoch 5845/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8183e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05845: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.8183e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.9235 - val_recall: 0.9206 - val_precision: 0.9233\n",
            "Epoch 5846/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0245e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05846: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.0245e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 5847/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05847: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.0044 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.6805 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 5848/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05848: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0237 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 1.8636 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_precision: 0.9000\n",
            "Epoch 5849/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05849: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0067 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 4.4100 - val_accuracy: 0.8235 - val_recall: 0.8235 - val_precision: 0.8284\n",
            "Epoch 5850/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05850: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0049 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 0.7729 - val_accuracy: 0.9500 - val_recall: 0.9471 - val_precision: 0.9499\n",
            "Epoch 5851/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05851: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0072 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 3.0584 - val_accuracy: 0.8412 - val_recall: 0.8412 - val_precision: 0.8462\n",
            "Epoch 5852/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 05852: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.0041 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 4.9277 - val_accuracy: 0.7765 - val_recall: 0.7765 - val_precision: 0.7788\n",
            "Epoch 5853/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05853: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0016 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 18.7166 - val_accuracy: 0.5324 - val_recall: 0.5294 - val_precision: 0.5357\n",
            "Epoch 5854/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05854: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0090 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 10.6257 - val_accuracy: 0.5794 - val_recall: 0.5794 - val_precision: 0.5811\n",
            "Epoch 5855/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05855: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0055 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 8.4251 - val_accuracy: 0.6059 - val_recall: 0.6059 - val_precision: 0.6077\n",
            "Epoch 5856/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5176e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05856: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5176e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 10.1325 - val_accuracy: 0.5912 - val_recall: 0.5912 - val_precision: 0.5912\n",
            "Epoch 5857/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05857: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0026 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 3.6029 - val_accuracy: 0.7647 - val_recall: 0.7647 - val_precision: 0.7647\n",
            "Epoch 5858/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3292e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05858: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.3292e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.1845 - val_accuracy: 0.8324 - val_recall: 0.8324 - val_precision: 0.8324\n",
            "Epoch 5859/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1477e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05859: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.1477e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8783 - val_accuracy: 0.8647 - val_recall: 0.8618 - val_precision: 0.8669\n",
            "Epoch 5860/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9020e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05860: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.9020e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.5261 - val_accuracy: 0.8912 - val_recall: 0.8912 - val_precision: 0.8938\n",
            "Epoch 5861/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4300e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05861: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4300e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1842 - val_accuracy: 0.9029 - val_recall: 0.9029 - val_precision: 0.9029\n",
            "Epoch 5862/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0999e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05862: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0999e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9176 - val_recall: 0.9147 - val_precision: 0.9201\n",
            "Epoch 5863/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2472e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05863: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.2472e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.9265 - val_recall: 0.9235 - val_precision: 0.9263\n",
            "Epoch 5864/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9888e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05864: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.9888e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.9324 - val_recall: 0.9324 - val_precision: 0.9351\n",
            "Epoch 5865/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0701e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05865: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.0701e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 5866/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7463e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05866: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.7463e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 5867/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4085e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05867: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4085e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 5868/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1046e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05868: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.1046e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 5869/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5274e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05869: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.5274e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 5870/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3172e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05870: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3172e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 5871/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0436e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05871: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0436e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9735\n",
            "Epoch 5872/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1349e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05872: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.1349e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9764\n",
            "Epoch 5873/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9880e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05873: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.9880e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5874/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.2381e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05874: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.2381e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5875/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4379e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05875: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.4379e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5876/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8701e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05876: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.8701e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5877/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4729e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05877: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.4729e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5878/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8348e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05878: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 5.8348e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5879/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4715e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05879: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.4715e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5880/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3307e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05880: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.3307e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9794 - val_recall: 0.9765 - val_precision: 0.9794\n",
            "Epoch 5881/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9794e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05881: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.9794e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9794 - val_recall: 0.9794 - val_precision: 0.9794\n",
            "Epoch 5882/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4250e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05882: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.4250e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9794 - val_recall: 0.9765 - val_precision: 0.9794\n",
            "Epoch 5883/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3406e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05883: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.3406e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9794\n",
            "Epoch 5884/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7013e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05884: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.7013e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5885/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5485e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05885: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.5485e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5886/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05886: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0099 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.2925 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 5887/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5150e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05887: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.5150e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9734\n",
            "Epoch 5888/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8524e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05888: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.8524e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9734\n",
            "Epoch 5889/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0945e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05889: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 8.0945e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5890/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971    \n",
            "Epoch 05890: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.1120 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971 - val_loss: 0.3123 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9675\n",
            "Epoch 5891/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05891: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0081 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 68.7648 - val_accuracy: 0.4441 - val_recall: 0.4441 - val_precision: 0.4441\n",
            "Epoch 5892/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05892: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 276ms/step - loss: 0.0236 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 72.4488 - val_accuracy: 0.4265 - val_recall: 0.4265 - val_precision: 0.4265\n",
            "Epoch 5893/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05893: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0119 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 44.9741 - val_accuracy: 0.4706 - val_recall: 0.4706 - val_precision: 0.4706\n",
            "Epoch 5894/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05894: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0070 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 24.2931 - val_accuracy: 0.4353 - val_recall: 0.4353 - val_precision: 0.4353\n",
            "Epoch 5895/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05895: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0023 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 17.6539 - val_accuracy: 0.4735 - val_recall: 0.4735 - val_precision: 0.4735\n",
            "Epoch 5896/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05896: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 14.4670 - val_accuracy: 0.5441 - val_recall: 0.5441 - val_precision: 0.5441\n",
            "Epoch 5897/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05897: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0011 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 13.7012 - val_accuracy: 0.5559 - val_recall: 0.5559 - val_precision: 0.5559\n",
            "Epoch 5898/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4999e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05898: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4999e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 11.7571 - val_accuracy: 0.5971 - val_recall: 0.5971 - val_precision: 0.5971\n",
            "Epoch 5899/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9510e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05899: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.9510e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 8.7957 - val_accuracy: 0.6618 - val_recall: 0.6618 - val_precision: 0.6618\n",
            "Epoch 5900/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05900: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0050 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 10.7627 - val_accuracy: 0.5882 - val_recall: 0.5882 - val_precision: 0.5900\n",
            "Epoch 5901/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05901: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0106 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 8.4045 - val_accuracy: 0.5941 - val_recall: 0.5941 - val_precision: 0.5959\n",
            "Epoch 5902/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 05902: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0086 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 3.2188 - val_accuracy: 0.7471 - val_recall: 0.7471 - val_precision: 0.7493\n",
            "Epoch 5903/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05903: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0045 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 2.6275 - val_accuracy: 0.8147 - val_recall: 0.8147 - val_precision: 0.8147\n",
            "Epoch 5904/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 05904: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 0.0116 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.7189 - val_accuracy: 0.8441 - val_recall: 0.8441 - val_precision: 0.8466\n",
            "Epoch 5905/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05905: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0050 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.1936 - val_accuracy: 0.8706 - val_recall: 0.8706 - val_precision: 0.8783\n",
            "Epoch 5906/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 05906: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0046 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 1.4875 - val_accuracy: 0.8706 - val_recall: 0.8676 - val_precision: 0.8728\n",
            "Epoch 5907/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 05907: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0035 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.2202 - val_accuracy: 0.9118 - val_recall: 0.9118 - val_precision: 0.9145\n",
            "Epoch 5908/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6426e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05908: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 266ms/step - loss: 3.6426e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.9324 - val_recall: 0.9324 - val_precision: 0.9379\n",
            "Epoch 5909/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.4862e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 1.0000\n",
            "Epoch 05909: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.4862e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9497\n",
            "Epoch 5910/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1433e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05910: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.1433e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9469\n",
            "Epoch 5911/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1440e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05911: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 5.1440e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 5912/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1752e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05912: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.1752e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9382\n",
            "Epoch 5913/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6216e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05913: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.6216e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 5914/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0836e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05914: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0836e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n",
            "Epoch 5915/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2289e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05915: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2289e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9499\n",
            "Epoch 5916/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0981e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05916: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.0981e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9499\n",
            "Epoch 5917/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3124e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05917: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3124e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 5918/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8443e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05918: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 275ms/step - loss: 1.8443e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 5919/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9118e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05919: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.9118e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 5920/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2942e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05920: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 2.2942e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 5921/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4174e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05921: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 4.4174e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6138 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 5922/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6069e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05922: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.6069e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5949 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9586\n",
            "Epoch 5923/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6158e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05923: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.6158e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.9588 - val_recall: 0.9529 - val_precision: 0.9586\n",
            "Epoch 5924/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3580e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05924: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.3580e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 5925/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2570e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05925: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2570e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 5926/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.6641e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05926: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.6641e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 5927/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2189e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05927: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2189e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 5928/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9642e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05928: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.9642e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 5929/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0732e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05929: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0732e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 5930/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5000e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05930: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.5000e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 5931/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4254e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05931: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4254e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 5932/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2851e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05932: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 5.2851e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 5933/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0975e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05933: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.0975e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 5934/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7561e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05934: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.7561e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 5935/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0594e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05935: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 9.0594e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 5936/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2551e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05936: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.2551e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9676 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 5937/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1946e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05937: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1946e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9676 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 5938/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8002e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05938: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.8002e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 5939/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1892e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05939: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1892e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 5940/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9682e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05940: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9682e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 5941/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1003e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05941: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.1003e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5942/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.7489e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05942: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 8.7489e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5943/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4356e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05943: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.4356e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5944/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0893e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05944: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.0893e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5945/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9895e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05945: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9895e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5946/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7449e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05946: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.7449e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5947/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3258e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05947: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.3258e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5948/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1435e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05948: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1435e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5949/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9635e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05949: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9635e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5950/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0246e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05950: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0246e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5951/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8164e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05951: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.8164e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5952/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0138e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05952: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.0138e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5953/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9072e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05953: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.9072e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5954/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4647e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05954: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.4647e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5955/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6658e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05955: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 6.6658e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5956/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2565e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05956: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.2565e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5957/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9750e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05957: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.9750e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5958/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.8412e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05958: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.8412e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5959/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7953e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05959: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.7953e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5960/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9621e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05960: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.9621e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5961/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9317e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05961: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9317e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5962/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2382e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05962: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.2382e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5963/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9948e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05963: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9948e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5964/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0540e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05964: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.0540e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5965/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0703e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05965: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.0703e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5966/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5139e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05966: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.5139e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5967/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.5081e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05967: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.5081e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5968/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7402e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05968: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.7402e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5969/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4560e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05969: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4560e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 5970/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7634e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05970: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.7634e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5971/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2561e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05971: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.2561e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5972/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3168e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05972: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.3168e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5973/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3935e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05973: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.3935e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5974/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0582e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05974: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0582e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5975/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3484e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05975: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 1.3484e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5976/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1497e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05976: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1497e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5977/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2375e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05977: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.2375e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5978/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1396e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05978: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.1396e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5979/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6789e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05979: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.6789e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5980/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0953e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05980: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.0953e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5981/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2102e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05981: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.2102e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5982/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3360e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05982: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3360e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5983/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5870e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05983: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.5870e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5984/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3160e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05984: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 8.3160e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5985/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4356e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05985: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.4356e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5986/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2386e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05986: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 5.2386e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5987/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8174e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05987: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.8174e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5988/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5061e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05988: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.5061e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5989/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0045e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05989: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.0045e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5990/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4861e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05990: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4861e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5991/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.1135e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05991: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 8.1135e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5992/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8887e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05992: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.8887e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5993/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5603e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05993: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.5603e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5994/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6204e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05994: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 2.6204e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5995/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9868e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05995: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 2.9868e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5996/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0873e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05996: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0873e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5997/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4042e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05997: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.4042e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5998/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1446e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05998: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.1446e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 5999/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0742e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 05999: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0742e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6000/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7974e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06000: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.7974e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6001/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.4862e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06001: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.4862e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6002/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4521e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06002: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.4521e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6003/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5480e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06003: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.5480e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6004/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1197e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06004: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.1197e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6005/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8299e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06005: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 5.8299e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6006/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3710e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06006: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.3710e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6007/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8612e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06007: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.8612e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6008/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4289e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06008: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.4289e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6009/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0146e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06009: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0146e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6010/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4740e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06010: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.4740e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6011/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.9340e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06011: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 8.9340e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6012/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9655e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06012: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 2.9655e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6013/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8409e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06013: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.8409e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6014/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5807e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06014: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5807e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6015/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.6677e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06015: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.6677e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6016/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9847e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06016: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.9847e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6017/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4468e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06017: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.4468e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6018/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4634e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06018: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.4634e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6019/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3419e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06019: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.3419e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6020/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4201e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06020: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 4.4201e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6021/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2875e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06021: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 2.2875e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6022/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0248e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06022: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 5.0248e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6023/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0599e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06023: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0599e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6024/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4040e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06024: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.4040e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6025/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9725e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06025: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.9725e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6026/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2122e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06026: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2122e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6027/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8052e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06027: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.8052e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6028/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.7832e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06028: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.7832e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6029/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9358e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06029: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 1.9358e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6030/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6385e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06030: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.6385e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6031/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1111e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06031: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.1111e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6032/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8207e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06032: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.8207e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6033/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6428e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06033: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 9.6428e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6034/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2732e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06034: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2732e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6035/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1305e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06035: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.1305e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6036/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6894e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06036: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.6894e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6037/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3174e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06037: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.3174e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9764\n",
            "Epoch 6038/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6813e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06038: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.6813e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9764\n",
            "Epoch 6039/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0911e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06039: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0911e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9764\n",
            "Epoch 6040/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.6358e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06040: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.6358e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9735 - val_recall: 0.9706 - val_precision: 0.9735\n",
            "Epoch 6041/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.2358e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06041: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.2358e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6042/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2568e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06042: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.2568e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6043/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9756e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06043: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 3.9756e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6044/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8058e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06044: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.8058e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6045/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9121e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06045: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.9121e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6046/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8147e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06046: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.8147e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6047/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2404e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06047: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2404e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6048/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8161e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06048: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.8161e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6049/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5719e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06049: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.5719e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6050/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8531e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06050: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.8531e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6051/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1557e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06051: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.1557e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6052/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9349e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06052: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.9349e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9764\n",
            "Epoch 6053/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9139e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06053: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.9139e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9764\n",
            "Epoch 6054/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9145e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06054: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.9145e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6055/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.9757e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06055: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.9757e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6056/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4289e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06056: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.4289e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6057/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2830e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06057: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2830e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6058/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1646e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06058: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1646e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6059/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6895e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06059: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.6895e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6060/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0544e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06060: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0544e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6061/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7887e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06061: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.7887e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6062/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3862e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06062: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3862e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6063/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2548e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06063: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2548e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6064/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.9483e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06064: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.9483e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6065/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1024e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06065: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1024e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6066/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3117e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06066: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.3117e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6067/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0725e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06067: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0725e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6068/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4684e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06068: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 8.4684e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6069/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4372e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06069: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4372e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6070/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4117e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06070: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.4117e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6071/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0773e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06071: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.0773e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6072/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7885e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06072: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.7885e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6073/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4214e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06073: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.4214e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6074/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9617e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06074: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.9617e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6075/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7425e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06075: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.7425e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6076/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0318e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06076: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 5.0318e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6077/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4402e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06077: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.4402e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6078/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0937e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06078: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0937e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6079/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4842e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06079: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4842e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6080/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4778e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06080: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.4778e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6081/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8550e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06081: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.8550e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6082/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9596e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06082: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.9596e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6083/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0366e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06083: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0366e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6084/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0205e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06084: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0205e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6085/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2387e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06085: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.2387e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6086/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9791e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06086: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.9791e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6087/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2861e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06087: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2861e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6088/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3518e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06088: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.3518e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6089/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0660e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06089: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0660e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6090/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0345e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06090: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.0345e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6091/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3510e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06091: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.3510e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6092/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5229e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06092: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.5229e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6093/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3791e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06093: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.3791e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6094/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7981e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06094: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.7981e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6095/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3176e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06095: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.3176e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6096/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3926e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06096: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3926e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6097/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.6394e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06097: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.6394e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6098/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.2151e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06098: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.2151e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6099/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6623e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06099: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6623e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6100/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9826e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06100: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.9826e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6101/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2328e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06101: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.2328e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6102/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3985e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06102: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3985e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6103/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3748e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06103: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.3748e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6104/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8992e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06104: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.8992e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6105/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5107e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06105: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.5107e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6106/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1678e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06106: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.1678e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6107/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9736e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06107: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.9736e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6108/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6208e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06108: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.6208e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6109/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0863e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06109: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 5.0863e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6110/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8248e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06110: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 1.8248e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6111/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8869e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06111: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.8869e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6112/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5987e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06112: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.5987e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6113/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1121e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06113: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.1121e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6114/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4583e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06114: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4583e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6115/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1912e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06115: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1912e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6116/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1003e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06116: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.1003e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6117/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4509e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06117: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4509e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6118/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7722e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06118: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.7722e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6119/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8345e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06119: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.8345e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6120/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9939e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06120: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.9939e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6121/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4909e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06121: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.4909e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6122/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1200e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06122: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.1200e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6123/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.4786e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06123: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 9.4786e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6124/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1156e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06124: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1156e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6125/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5293e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06125: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.5293e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6126/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4733e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06126: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.4733e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6127/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8199e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06127: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8199e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6128/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0190e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06128: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0190e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6129/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.9634e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06129: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.9634e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6130/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5461e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06130: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.5461e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6131/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4640e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06131: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 2.4640e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6132/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4491e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06132: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4491e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6133/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3335e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06133: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3335e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6134/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2763e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06134: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.2763e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6135/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5773e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06135: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.5773e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6136/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0761e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06136: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.0761e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6137/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.7860e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06137: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 9.7860e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6138/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5070e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06138: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.5070e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6139/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9321e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06139: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.9321e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6140/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4099e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06140: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.4099e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6141/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9339e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06141: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.9339e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6142/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1246e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06142: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 297ms/step - loss: 6.1246e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6143/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2270e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06143: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.2270e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6144/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1449e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06144: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.1449e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6145/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6366e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06145: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.6366e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6146/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4327e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06146: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4327e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6147/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8763e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06147: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.8763e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6148/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3361e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06148: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3361e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6149/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6168e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06149: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.6168e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6150/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2866e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06150: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 4.2866e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6151/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.4434e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06151: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.4434e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6152/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1977e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06152: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.1977e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6153/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0514e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06153: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.0514e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6154/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5315e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06154: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.5315e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6155/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0996e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06155: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0996e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6156/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4049e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06156: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.4049e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6157/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7088e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06157: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.7088e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6158/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1186e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06158: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 3.1186e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6159/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5930e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06159: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.5930e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6160/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1416e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06160: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1416e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6161/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3254e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06161: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 3.3254e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6162/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1639e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06162: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1639e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6163/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0023e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06163: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0023e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6164/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.1651e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06164: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.1651e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6165/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8207e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06165: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 2.8207e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6166/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6484e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06166: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.6484e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6167/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5694e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06167: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.5694e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6168/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4214e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06168: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.4214e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6169/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2904e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06169: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 1.2904e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6170/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5915e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06170: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.5915e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6171/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2781e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06171: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.2781e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6172/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3278e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06172: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 8.3278e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6173/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5505e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06173: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.5505e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6174/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.6060e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06174: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 8.6060e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6175/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4297e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06175: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.4297e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6176/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.3991e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06176: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.3991e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6177/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0730e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06177: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.0730e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6178/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3466e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06178: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.3466e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6179/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0298e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06179: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.0298e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6180/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6173e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06180: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.6173e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6181/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.4561e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06181: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.4561e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6182/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3278e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06182: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.3278e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6183/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.0710e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06183: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.0710e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6184/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1952e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06184: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.1952e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6185/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.9142e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06185: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.9142e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6186/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5780e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06186: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.5780e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6187/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0134e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06187: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0134e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6188/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1672e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06188: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.1672e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6189/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0290e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06189: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.0290e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6190/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4348e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06190: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4348e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6191/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.0277e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06191: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.0277e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6192/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1223e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06192: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.1223e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6193/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2123e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06193: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2123e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6194/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1985e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06194: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1985e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6195/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2452e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06195: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.2452e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9735 - val_recall: 0.9706 - val_precision: 0.9735\n",
            "Epoch 6196/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3870e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06196: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.3870e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6197/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9504e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06197: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.9504e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9735 - val_recall: 0.9706 - val_precision: 0.9735\n",
            "Epoch 6198/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2984e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06198: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 1.2984e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6199/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8703e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06199: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 8.8703e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6200/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4455e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06200: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.4455e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6201/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8175e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06201: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8175e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6202/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.9019e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06202: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.9019e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6203/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7404e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06203: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.7404e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6204/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9709e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06204: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.9709e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6205/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3343e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06205: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.3343e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6206/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4319e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06206: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 1.4319e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6207/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8726e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06207: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 8.8726e-09 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6208/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1244e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06208: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.1244e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6209/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0644e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06209: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.0644e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6210/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1157e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06210: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1157e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6211/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.6596e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06211: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.6596e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.9124 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6212/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5899e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06212: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.5899e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2814 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9440\n",
            "Epoch 6213/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7182e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06213: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.7182e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6214/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3340e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06214: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.3340e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6215/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5937e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06215: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.5937e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6216/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0472e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06216: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.0472e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8710 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6217/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0371e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06217: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0371e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6218/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0310e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06218: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.0310e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6219/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3961e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06219: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.3961e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6220/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06220: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0035 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 5.9307 - val_accuracy: 0.7824 - val_recall: 0.7794 - val_precision: 0.7817\n",
            "Epoch 6221/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06221: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0072 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 3.1170 - val_accuracy: 0.8324 - val_recall: 0.8324 - val_precision: 0.8324\n",
            "Epoch 6222/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9978\n",
            "Epoch 06222: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0371 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9978 - val_loss: 0.5503 - val_accuracy: 0.9676 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6223/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 06223: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0056 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 1.4220 - val_accuracy: 0.9176 - val_recall: 0.9176 - val_precision: 0.9176\n",
            "Epoch 6224/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971\n",
            "Epoch 06224: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0180 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971 - val_loss: 166.8923 - val_accuracy: 0.0912 - val_recall: 0.0912 - val_precision: 0.0912\n",
            "Epoch 6225/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971\n",
            "Epoch 06225: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0111 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971 - val_loss: 199.5420 - val_accuracy: 0.0941 - val_recall: 0.0941 - val_precision: 0.0941\n",
            "Epoch 6226/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06226: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0073 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 147.9633 - val_accuracy: 0.1353 - val_recall: 0.1353 - val_precision: 0.1353\n",
            "Epoch 6227/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9971 - recall: 0.9963 - precision: 0.9971\n",
            "Epoch 06227: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0113 - accuracy: 0.9971 - recall: 0.9963 - precision: 0.9971 - val_loss: 95.7598 - val_accuracy: 0.1882 - val_recall: 0.1882 - val_precision: 0.1882\n",
            "Epoch 6228/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06228: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0036 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 59.1380 - val_accuracy: 0.2618 - val_recall: 0.2618 - val_precision: 0.2618\n",
            "Epoch 6229/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9698e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06229: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.9698e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 35.9949 - val_accuracy: 0.3294 - val_recall: 0.3294 - val_precision: 0.3294\n",
            "Epoch 6230/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6259e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06230: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6259e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 21.8478 - val_accuracy: 0.4118 - val_recall: 0.4118 - val_precision: 0.4130\n",
            "Epoch 6231/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.8440e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06231: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 9.8440e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 12.4385 - val_accuracy: 0.5500 - val_recall: 0.5500 - val_precision: 0.5500\n",
            "Epoch 6232/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4525e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06232: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.4525e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 7.2966 - val_accuracy: 0.6559 - val_recall: 0.6559 - val_precision: 0.6559\n",
            "Epoch 6233/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6311e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06233: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.6311e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 4.3141 - val_accuracy: 0.7412 - val_recall: 0.7412 - val_precision: 0.7412\n",
            "Epoch 6234/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06234: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0032 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 3.3743 - val_accuracy: 0.7794 - val_recall: 0.7765 - val_precision: 0.7811\n",
            "Epoch 6235/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06235: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0689 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 3.0620 - val_accuracy: 0.8206 - val_recall: 0.8206 - val_precision: 0.8230\n",
            "Epoch 6236/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971\n",
            "Epoch 06236: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 0.0201 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971 - val_loss: 6.2222 - val_accuracy: 0.6941 - val_recall: 0.6941 - val_precision: 0.6962\n",
            "Epoch 6237/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 06237: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0554 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 2.8841 - val_accuracy: 0.8912 - val_recall: 0.8882 - val_precision: 0.8935\n",
            "Epoch 6238/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971\n",
            "Epoch 06238: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0298 - accuracy: 0.9971 - recall: 0.9971 - precision: 0.9971 - val_loss: 1.8556 - val_accuracy: 0.8882 - val_recall: 0.8882 - val_precision: 0.8935\n",
            "Epoch 6239/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06239: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0028 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 2.0322 - val_accuracy: 0.8647 - val_recall: 0.8618 - val_precision: 0.8643\n",
            "Epoch 6240/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06240: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0098 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.7385 - val_accuracy: 0.8794 - val_recall: 0.8765 - val_precision: 0.8791\n",
            "Epoch 6241/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0392e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06241: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 304ms/step - loss: 8.0392e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.3072 - val_accuracy: 0.9029 - val_recall: 0.9029 - val_precision: 0.9056\n",
            "Epoch 6242/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06242: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 0.0019 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.9484 - val_accuracy: 0.9176 - val_recall: 0.9176 - val_precision: 0.9286\n",
            "Epoch 6243/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0536e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06243: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0536e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.9382 - val_recall: 0.9353 - val_precision: 0.9436\n",
            "Epoch 6244/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7481e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06244: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.7481e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9582\n",
            "Epoch 6245/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5070e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06245: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.5070e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9586\n",
            "Epoch 6246/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5638e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06246: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.5638e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9674\n",
            "Epoch 6247/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4541e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06247: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4541e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9704\n",
            "Epoch 6248/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.1225e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06248: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 8.1225e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9734\n",
            "Epoch 6249/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7144e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06249: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.7144e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9734\n",
            "Epoch 6250/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2830e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06250: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.2830e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6251/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0679e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06251: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.0679e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9734\n",
            "Epoch 6252/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06252: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0028 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.3964 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6253/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3633e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06253: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.3633e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6254/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8538e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06254: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.8538e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6255/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5473e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06255: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.5473e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6256/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9528e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06256: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.9528e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6257/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06257: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0164 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 2.6793 - val_accuracy: 0.9118 - val_recall: 0.9088 - val_precision: 0.9115\n",
            "Epoch 6258/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06258: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0026 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 7.0639 - val_accuracy: 0.8441 - val_recall: 0.8441 - val_precision: 0.8441\n",
            "Epoch 6259/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6491e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06259: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 2.6491e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.9249 - val_accuracy: 0.8912 - val_recall: 0.8882 - val_precision: 0.8909\n",
            "Epoch 6260/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1605e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06260: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.1605e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.5401 - val_accuracy: 0.9059 - val_recall: 0.9059 - val_precision: 0.9059\n",
            "Epoch 6261/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1165e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06261: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1165e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.9294 - val_recall: 0.9294 - val_precision: 0.9294\n",
            "Epoch 6262/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3337e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06262: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 6.3337e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2199 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9382\n",
            "Epoch 6263/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5802e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06263: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.5802e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6264/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0930e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06264: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0930e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6265/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7372e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06265: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.7372e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6266/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9685e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06266: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9685e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6267/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4550e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06267: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.4550e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6268/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5378e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06268: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5378e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6269/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9860e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06269: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9860e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6270/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9084e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06270: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 9.9084e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6271/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3404e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06271: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3404e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6272/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3698e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06272: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.3698e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6273/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5410e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06273: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.5410e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6274/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.8239e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06274: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.8239e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6275/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1120e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06275: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.1120e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6276/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06276: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.7859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6277/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6981e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06277: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.6981e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6278/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6969e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06278: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6969e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6279/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1920e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06279: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1920e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6280/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8714e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06280: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.8714e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6281/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7933e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06281: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.7933e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6282/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5805e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06282: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.5805e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6283/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0832e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06283: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 4.0832e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6284/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0181e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06284: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 266ms/step - loss: 2.0181e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6285/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0105e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06285: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 9.0105e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6286/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7744e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06286: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.7744e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6287/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3681e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06287: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.3681e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6288/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8718e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06288: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.8718e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6289/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06289: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0101 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.4297 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6290/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.5958e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06290: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.5958e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.9206 - val_recall: 0.9206 - val_precision: 0.9233\n",
            "Epoch 6291/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06291: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0026 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 3.6729 - val_accuracy: 0.8441 - val_recall: 0.8441 - val_precision: 0.8491\n",
            "Epoch 6292/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4043e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06292: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 5.4043e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.3953 - val_accuracy: 0.8265 - val_recall: 0.8235 - val_precision: 0.8260\n",
            "Epoch 6293/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8918e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06293: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.8918e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.7791 - val_accuracy: 0.8941 - val_recall: 0.8941 - val_precision: 0.8994\n",
            "Epoch 6294/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.2795e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06294: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.2795e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2675 - val_accuracy: 0.9294 - val_recall: 0.9265 - val_precision: 0.9292\n",
            "Epoch 6295/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4358e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06295: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4358e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.9353 - val_recall: 0.9353 - val_precision: 0.9381\n",
            "Epoch 6296/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8106e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06296: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 2.8106e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9382\n",
            "Epoch 6297/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5338e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06297: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.5338e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.9471 - val_recall: 0.9441 - val_precision: 0.9469\n",
            "Epoch 6298/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3796e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06298: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.3796e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6299/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7268e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06299: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 4.7268e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6300/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4944e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06300: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.4944e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6301/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1440e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06301: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 5.1440e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6302/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3422e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06302: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.3422e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6303/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8010e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06303: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.8010e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9615\n",
            "Epoch 6304/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0989e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06304: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0989e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6305/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7476e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06305: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 266ms/step - loss: 3.7476e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6306/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6262e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06306: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.6262e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6307/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0625e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06307: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.0625e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6308/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.0508e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06308: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.0508e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6309/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6327e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06309: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.6327e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6310/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9506e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06310: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.9506e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6311/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7985e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06311: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.7985e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6312/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3672e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06312: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.3672e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6313/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0004e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06313: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.0004e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6314/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0677e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06314: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 8.0677e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6315/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06315: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0015 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5612 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6316/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6924e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06316: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.6924e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5458 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6317/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0707e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06317: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0707e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6318/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9439e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06318: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.9439e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6319/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4382e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06319: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.4382e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6320/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7079e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06320: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.7079e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6321/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4556e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06321: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4556e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6322/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1194e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06322: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.1194e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6323/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7926e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06323: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.7926e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6324/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0303e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06324: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.0303e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6325/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2372e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06325: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2372e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6326/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2382e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06326: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 4.2382e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9735\n",
            "Epoch 6327/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.7654e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06327: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 9.7654e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6328/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3953e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06328: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 7.3953e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.4519 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6329/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7515e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06329: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.7515e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 6330/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06330: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0025 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 0.5019 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6331/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.6604e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06331: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.6604e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.9353 - val_recall: 0.9353 - val_precision: 0.9353\n",
            "Epoch 6332/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3387e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06332: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 4.3387e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.9294 - val_recall: 0.9294 - val_precision: 0.9294\n",
            "Epoch 6333/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4087e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06333: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.4087e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.9353 - val_recall: 0.9353 - val_precision: 0.9353\n",
            "Epoch 6334/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8373e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06334: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 8.8373e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5840 - val_accuracy: 0.9353 - val_recall: 0.9353 - val_precision: 0.9353\n",
            "Epoch 6335/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1651e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06335: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 5.1651e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9382\n",
            "Epoch 6336/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3316e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06336: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.3316e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 6337/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1914e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06337: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1914e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 6338/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5541e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06338: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.5541e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6339/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9514e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06339: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.9514e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6340/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4232e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06340: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 1.4232e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6341/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3649e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06341: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.3649e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6342/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7622e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06342: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.7622e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6343/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9203e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06343: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9203e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6344/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0313e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06344: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0313e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6345/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3616e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06345: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3616e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6346/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7178e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06346: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.7178e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6347/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5687e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06347: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 4.5687e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6348/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0208e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06348: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0208e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6349/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3564e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06349: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.3564e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6350/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6533e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06350: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.6533e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6351/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3589e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06351: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.3589e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6352/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2328e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06352: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.2328e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6353/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8866e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06353: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.8866e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6354/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.9902e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06354: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 8.9902e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6355/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7222e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06355: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.7222e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6356/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2039e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06356: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.2039e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6357/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3947e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06357: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3947e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6358/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0128e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06358: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.0128e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5689 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6359/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.4679e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06359: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.4679e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5491 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6360/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2732e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06360: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.2732e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6361/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9048e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06361: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.9048e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5826 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6362/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1144e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06362: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.1144e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6363/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6467e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06363: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6467e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6364/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9940e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06364: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.9940e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6365/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3967e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06365: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.3967e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6366/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2873e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06366: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2873e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6367/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6251e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06367: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.6251e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6368/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8625e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06368: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 1.8625e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6369/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0194e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06369: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.0194e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6370/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.0137e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06370: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.0137e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5390 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6371/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9273e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06371: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.9273e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6372/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3676e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06372: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.3676e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6373/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7915e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06373: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.7915e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6374/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3607e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06374: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3607e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6375/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5020e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06375: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 5.5020e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6376/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06376: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.0067 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.4581 - val_accuracy: 0.9765 - val_recall: 0.9765 - val_precision: 0.9765\n",
            "Epoch 6377/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06377: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0015 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 2.4341 - val_accuracy: 0.8500 - val_recall: 0.8500 - val_precision: 0.8525\n",
            "Epoch 6378/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6841e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06378: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6841e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 5.2792 - val_accuracy: 0.7265 - val_recall: 0.7265 - val_precision: 0.7286\n",
            "Epoch 6379/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.7327e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06379: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.7327e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 4.0865 - val_accuracy: 0.7765 - val_recall: 0.7765 - val_precision: 0.7765\n",
            "Epoch 6380/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06380: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0228 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 9.4332 - val_accuracy: 0.7000 - val_recall: 0.7000 - val_precision: 0.7021\n",
            "Epoch 6381/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0954e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06381: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.0954e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 9.5621 - val_accuracy: 0.6941 - val_recall: 0.6941 - val_precision: 0.6962\n",
            "Epoch 6382/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0569e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06382: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0569e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 6.9180 - val_accuracy: 0.7353 - val_recall: 0.7353 - val_precision: 0.7353\n",
            "Epoch 6383/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6723e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06383: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.6723e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 4.1777 - val_accuracy: 0.7735 - val_recall: 0.7735 - val_precision: 0.7758\n",
            "Epoch 6384/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06384: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.9308 - val_accuracy: 0.8324 - val_recall: 0.8324 - val_precision: 0.8324\n",
            "Epoch 6385/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06385: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0172 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 3.3529 - val_accuracy: 0.7882 - val_recall: 0.7882 - val_precision: 0.7906\n",
            "Epoch 6386/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06386: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 0.0048 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 4.3438 - val_accuracy: 0.7735 - val_recall: 0.7735 - val_precision: 0.7758\n",
            "Epoch 6387/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1634e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06387: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1634e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.3519 - val_accuracy: 0.8265 - val_recall: 0.8265 - val_precision: 0.8265\n",
            "Epoch 6388/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7470e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06388: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 5.7470e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.4873 - val_accuracy: 0.8735 - val_recall: 0.8706 - val_precision: 0.8783\n",
            "Epoch 6389/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2603e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06389: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2603e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7915 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_precision: 0.9027\n",
            "Epoch 6390/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8684e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06390: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.8684e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2954 - val_accuracy: 0.9118 - val_recall: 0.9118 - val_precision: 0.9118\n",
            "Epoch 6391/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06391: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0032 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.8121 - val_accuracy: 0.8912 - val_recall: 0.8912 - val_precision: 0.8964\n",
            "Epoch 6392/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06392: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0125 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 3.3626 - val_accuracy: 0.8294 - val_recall: 0.8294 - val_precision: 0.8294\n",
            "Epoch 6393/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06393: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0030 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 3.0878 - val_accuracy: 0.8588 - val_recall: 0.8588 - val_precision: 0.8588\n",
            "Epoch 6394/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06394: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 2.2450 - val_accuracy: 0.9265 - val_recall: 0.9265 - val_precision: 0.9265\n",
            "Epoch 6395/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06395: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0022 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 2.1286 - val_accuracy: 0.9294 - val_recall: 0.9294 - val_precision: 0.9294\n",
            "Epoch 6396/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6900e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06396: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.6900e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9037 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9382\n",
            "Epoch 6397/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06397: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0184 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.5625 - val_accuracy: 0.9353 - val_recall: 0.9324 - val_precision: 0.9351\n",
            "Epoch 6398/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6548e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06398: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.6548e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.9353 - val_recall: 0.9353 - val_precision: 0.9381\n",
            "Epoch 6399/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06399: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0017 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.0252 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9438\n",
            "Epoch 6400/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0826e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06400: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 3.0826e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.9382 - val_recall: 0.9382 - val_precision: 0.9382\n",
            "Epoch 6401/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06401: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0019 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 1.3889 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 6402/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9963 - recall: 0.9963 - precision: 0.9963\n",
            "Epoch 06402: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0270 - accuracy: 0.9963 - recall: 0.9963 - precision: 0.9963 - val_loss: 0.4889 - val_accuracy: 0.9618 - val_recall: 0.9559 - val_precision: 0.9644\n",
            "Epoch 6403/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06403: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0010 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5533 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6404/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06404: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0045 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.0644 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_precision: 0.9027\n",
            "Epoch 6405/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06405: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.0012 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 2.2596 - val_accuracy: 0.8765 - val_recall: 0.8765 - val_precision: 0.8817\n",
            "Epoch 6406/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.9535e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06406: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 7.9535e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.5629 - val_accuracy: 0.8824 - val_recall: 0.8824 - val_precision: 0.8824\n",
            "Epoch 6407/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4857e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06407: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 8.4857e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.5832 - val_accuracy: 0.8824 - val_recall: 0.8824 - val_precision: 0.8850\n",
            "Epoch 6408/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6896e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06408: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.6896e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.4762 - val_accuracy: 0.8853 - val_recall: 0.8824 - val_precision: 0.8850\n",
            "Epoch 6409/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6683e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06409: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.6683e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.3280 - val_accuracy: 0.8882 - val_recall: 0.8853 - val_precision: 0.8879\n",
            "Epoch 6410/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2206e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06410: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.2206e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.8882 - val_recall: 0.8824 - val_precision: 0.8876\n",
            "Epoch 6411/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06411: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.8334 - val_accuracy: 0.8912 - val_recall: 0.8912 - val_precision: 0.8912\n",
            "Epoch 6412/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3932e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06412: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.3932e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2452 - val_accuracy: 0.9000 - val_recall: 0.9000 - val_precision: 0.9027\n",
            "Epoch 6413/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6739e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06413: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.6739e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.4604 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6414/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8243e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06414: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.8243e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6415/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.7394e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06415: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 8.7394e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.9500 - val_recall: 0.9471 - val_precision: 0.9527\n",
            "Epoch 6416/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1265e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06416: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 3.1265e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9500 - val_recall: 0.9471 - val_precision: 0.9499\n",
            "Epoch 6417/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3578e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06417: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3578e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9529 - val_recall: 0.9500 - val_precision: 0.9528\n",
            "Epoch 6418/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2822e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06418: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2822e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6419/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0373e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06419: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.0373e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6420/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0814e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06420: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.0814e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6421/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1165e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06421: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.1165e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6422/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2075e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06422: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.2075e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6423/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.5815e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06423: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.5815e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6424/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0895e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06424: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 266ms/step - loss: 9.0895e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6425/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6773e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06425: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.6773e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6426/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0410e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06426: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 5.0410e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6427/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9461e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06427: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9461e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6428/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9588e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06428: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 265ms/step - loss: 1.9588e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9676 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6429/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4704e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06429: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4704e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9676 - val_recall: 0.9618 - val_precision: 0.9675\n",
            "Epoch 6430/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6058e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06430: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6058e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6431/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.0875e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06431: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.0875e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9647 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6432/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2564e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06432: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.2564e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6433/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0241e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06433: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.0241e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9646\n",
            "Epoch 6434/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7763e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06434: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.7763e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6435/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2975e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06435: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.2975e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6436/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0930e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06436: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.0930e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6437/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5734e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06437: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.5734e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6438/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2184e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06438: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2184e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6439/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4150e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06439: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4150e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6440/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8161e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06440: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 8.8161e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6441/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5170e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06441: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5170e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6442/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9649e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06442: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.9649e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6443/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6742e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06443: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.6742e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6444/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7045e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06444: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.7045e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6445/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5039e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06445: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5039e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6446/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1713e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06446: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.1713e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6447/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6516e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06447: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.6516e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5238 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6448/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3045e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06448: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 6.3045e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6449/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3089e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06449: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.3089e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6450/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2072e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06450: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.2072e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5865 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6451/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7734e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06451: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.7734e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6452/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0035e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06452: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.0035e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6453/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6755e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06453: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 9.6755e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6454/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1634e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06454: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.1634e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6455/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.0029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06455: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.0029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6456/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.7970e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06456: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.7970e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6457/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6154e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06457: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.6154e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5861 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6458/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5281e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06458: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.5281e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6459/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6043e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06459: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.6043e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6460/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2220e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06460: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 5.2220e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6461/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06461: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0012 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.5629 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6462/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1834e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06462: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.1834e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6463/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4444e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06463: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.4444e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6464/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985    \n",
            "Epoch 06464: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0638 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 1.1488 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 6465/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2441e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06465: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.2441e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 117.9574 - val_accuracy: 0.3824 - val_recall: 0.3824 - val_precision: 0.3824\n",
            "Epoch 6466/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06466: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0086 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 98.3568 - val_accuracy: 0.3147 - val_recall: 0.3147 - val_precision: 0.3147\n",
            "Epoch 6467/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9993\n",
            "Epoch 06467: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0090 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9993 - val_loss: 100.2164 - val_accuracy: 0.2147 - val_recall: 0.2147 - val_precision: 0.2147\n",
            "Epoch 6468/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8240e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06468: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.8240e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 76.9876 - val_accuracy: 0.3118 - val_recall: 0.3118 - val_precision: 0.3118\n",
            "Epoch 6469/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1289e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06469: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.1289e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 55.9104 - val_accuracy: 0.4029 - val_recall: 0.4029 - val_precision: 0.4029\n",
            "Epoch 6470/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06470: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0040 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 39.9355 - val_accuracy: 0.4765 - val_recall: 0.4765 - val_precision: 0.4765\n",
            "Epoch 6471/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06471: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0014 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 28.6269 - val_accuracy: 0.5294 - val_recall: 0.5294 - val_precision: 0.5294\n",
            "Epoch 6472/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06472: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0185 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 17.2284 - val_accuracy: 0.6029 - val_recall: 0.6029 - val_precision: 0.6029\n",
            "Epoch 6473/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3676e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06473: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.3676e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 10.2756 - val_accuracy: 0.6765 - val_recall: 0.6765 - val_precision: 0.6765\n",
            "Epoch 6474/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7960e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06474: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 266ms/step - loss: 6.7960e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 6.5774 - val_accuracy: 0.7882 - val_recall: 0.7882 - val_precision: 0.7882\n",
            "Epoch 6475/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06475: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 0.0140 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 5.4563 - val_accuracy: 0.8088 - val_recall: 0.8059 - val_precision: 0.8083\n",
            "Epoch 6476/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06476: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0024 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 5.0652 - val_accuracy: 0.8206 - val_recall: 0.8206 - val_precision: 0.8206\n",
            "Epoch 6477/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8284e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06477: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.8284e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 4.0138 - val_accuracy: 0.8353 - val_recall: 0.8353 - val_precision: 0.8353\n",
            "Epoch 6478/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9187e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06478: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.9187e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.0139 - val_accuracy: 0.8529 - val_recall: 0.8529 - val_precision: 0.8529\n",
            "Epoch 6479/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8974e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06479: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.8974e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.2288 - val_accuracy: 0.8735 - val_recall: 0.8735 - val_precision: 0.8761\n",
            "Epoch 6480/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1484e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06480: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.1484e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6783 - val_accuracy: 0.8971 - val_recall: 0.8971 - val_precision: 0.8997\n",
            "Epoch 6481/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9276e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06481: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.9276e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.2981 - val_accuracy: 0.9206 - val_recall: 0.9206 - val_precision: 0.9233\n",
            "Epoch 6482/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2478e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06482: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2478e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 6483/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.1643e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06483: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.1643e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9414 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6484/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2075e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06484: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2075e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8265 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6485/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1372e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06485: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 5.1372e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6486/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06486: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0027 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.7991 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n",
            "Epoch 6487/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8506e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06487: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.8506e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.7148 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n",
            "Epoch 6488/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7195e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06488: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.7195e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6489/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.2241e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06489: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 298ms/step - loss: 9.2241e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9529\n",
            "Epoch 6490/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3419e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06490: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 7.3419e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6491/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06491: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0012 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.7925 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 6492/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3334e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06492: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.3334e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 6493/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1172e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06493: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.1172e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 6494/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0067e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06494: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 8.0067e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7517 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 6495/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1493e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06495: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.1493e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
            "Epoch 6496/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3666e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06496: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.3666e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6497/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3694e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06497: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.3694e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6321 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6498/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9127e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06498: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.9127e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6499/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4207e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06499: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.4207e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n",
            "Epoch 6500/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1530e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06500: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1530e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n",
            "Epoch 6501/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8553e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06501: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.8553e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n",
            "Epoch 6502/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9449e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06502: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.9449e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.9500 - val_recall: 0.9500 - val_precision: 0.9528\n",
            "Epoch 6503/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5350e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06503: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.5350e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.9529 - val_recall: 0.9500 - val_precision: 0.9556\n",
            "Epoch 6504/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.9056e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06504: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.9056e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6505/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1778e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06505: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1778e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6506/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9938e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06506: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.9938e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9529 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6507/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0250e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06507: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.0250e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6508/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7446e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06508: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.7446e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6509/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1327e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06509: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.1327e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6510/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0704e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06510: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.0704e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6511/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0210e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06511: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.0210e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6512/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0454e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06512: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0454e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9558\n",
            "Epoch 6513/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.9943e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06513: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.9943e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9559 - val_recall: 0.9529 - val_precision: 0.9586\n",
            "Epoch 6514/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3925e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06514: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 4.3925e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9588 - val_recall: 0.9529 - val_precision: 0.9586\n",
            "Epoch 6515/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0915e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06515: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.0915e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6516/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0595e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06516: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.0595e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6517/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0005e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06517: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.0005e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6518/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.6337e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06518: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 7.6337e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6519/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1056e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06519: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 2.1056e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9588 - val_recall: 0.9559 - val_precision: 0.9587\n",
            "Epoch 6520/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0987e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06520: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.0987e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6521/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6498e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06521: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.6498e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6522/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7596e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06522: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.7596e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6523/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6180e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06523: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.6180e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6524/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.6258e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06524: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.6258e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6525/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.2555e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06525: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.2555e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.4091 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6526/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5349e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06526: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.5349e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6527/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0516e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06527: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.0516e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6528/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6404e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06528: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.6404e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6529/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4833e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06529: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4833e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6530/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3296e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06530: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.3296e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6531/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6154e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06531: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.6154e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6532/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9439e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06532: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.9439e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6533/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7620e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06533: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.7620e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6534/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1766e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06534: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1766e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6535/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8650e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06535: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.8650e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6536/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0901e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06536: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.0901e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6537/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.3508e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06537: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 5.3508e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6538/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8429e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06538: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.8429e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6539/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5243e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06539: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5243e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6540/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8826e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06540: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.8826e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6541/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5532e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06541: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.5532e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6542/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0480e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06542: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0480e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6543/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5961e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06543: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.5961e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6544/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9587e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06544: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.9587e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6545/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3317e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06545: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3317e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6546/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7354e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06546: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 276ms/step - loss: 4.7354e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6547/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1762e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06547: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.1762e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6548/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1230e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06548: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1230e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6549/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6087e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06549: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 6.6087e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6550/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2124e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06550: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.2124e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6551/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1511e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06551: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.1511e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6552/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8125e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06552: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 1.8125e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6553/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3967e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06553: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3967e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6554/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3423e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06554: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3423e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6555/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5613e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06555: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.5613e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6556/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3868e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06556: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.3868e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6557/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6632e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06557: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.6632e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6558/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3639e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06558: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.3639e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6559/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0340e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06559: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.0340e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6560/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4893e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06560: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 8.4893e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6561/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1553e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06561: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.1553e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6562/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2972e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06562: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.2972e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6563/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9066e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06563: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.9066e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6564/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4031e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06564: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.4031e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6565/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.3791e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06565: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.3791e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6566/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4902e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06566: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 8.4902e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6567/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8405e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06567: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.8405e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6568/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3595e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06568: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 1.3595e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6569/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3134e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06569: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3134e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6570/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4083e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06570: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.4083e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6571/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2506e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06571: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.2506e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6572/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7807e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06572: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.7807e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6573/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4610e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06573: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.4610e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6574/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1190e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06574: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.1190e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6575/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8440e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06575: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.8440e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6576/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6582e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06576: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 4.6582e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6577/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1018e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06577: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.1018e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6578/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6972e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06578: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.6972e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6579/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4780e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06579: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.4780e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6580/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5638e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06580: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.5638e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6581/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0621e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06581: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0621e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6582/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7418e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06582: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.7418e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6583/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.7284e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06583: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.7284e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6584/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7494e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06584: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 1.7494e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6585/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8957e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06585: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.8957e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6586/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.2634e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06586: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.2634e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6587/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1776e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06587: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.1776e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6588/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8788e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06588: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 7.8788e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.4004 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6589/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1692e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06589: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 275ms/step - loss: 1.1692e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6590/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6286e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06590: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.6286e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6591/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4773e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06591: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4773e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6592/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0966e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06592: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.0966e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6593/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0531e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06593: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.0531e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6594/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7051e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06594: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 1.7051e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6595/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5372e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06595: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.5372e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6596/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8040e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06596: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8040e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6597/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0076e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06597: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0076e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6598/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2408e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06598: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2408e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6599/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8959e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06599: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.8959e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6600/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5535e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06600: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.5535e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6601/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.0914e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06601: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.0914e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6602/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8935e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06602: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.8935e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6603/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1886e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06603: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1886e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6604/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06604: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.1859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6605/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2454e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06605: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2454e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6606/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0866e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06606: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.0866e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6607/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5955e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06607: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5955e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6608/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.0825e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06608: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.0825e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6609/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1159e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06609: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.1159e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6610/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8473e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06610: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8473e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6611/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5163e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06611: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.5163e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6612/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7516e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06612: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.7516e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6613/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7503e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06613: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.7503e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6614/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0497e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06614: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.0497e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6615/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0669e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06615: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.0669e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6616/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.6518e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06616: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.6518e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6617/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1030e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06617: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.1030e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6618/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2958e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06618: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.2958e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6619/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8426e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06619: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.8426e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6620/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4575e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06620: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.4575e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6621/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.1258e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06621: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 6.1258e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6622/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6066e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06622: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.6066e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6623/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0726e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06623: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0726e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6624/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8210e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06624: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.8210e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6625/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6825e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06625: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.6825e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6626/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6003e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06626: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.6003e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6627/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.8687e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06627: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 9.8687e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6628/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2383e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06628: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.2383e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6629/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.2594e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06629: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.2594e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6630/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3001e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06630: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3001e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6631/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6668e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06631: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.6668e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6632/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06632: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0301 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 9.0838 - val_accuracy: 0.7765 - val_recall: 0.7765 - val_precision: 0.7765\n",
            "Epoch 6633/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5968e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06633: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5968e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 16.0792 - val_accuracy: 0.6824 - val_recall: 0.6824 - val_precision: 0.6824\n",
            "Epoch 6634/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06634: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 0.0014 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 13.2717 - val_accuracy: 0.7176 - val_recall: 0.7176 - val_precision: 0.7176\n",
            "Epoch 6635/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6745e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06635: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 6.6745e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 4.4942 - val_accuracy: 0.8676 - val_recall: 0.8647 - val_precision: 0.8673\n",
            "Epoch 6636/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06636: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0020 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 1.8284 - val_accuracy: 0.9265 - val_recall: 0.9265 - val_precision: 0.9265\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9130e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06637: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9130e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.9412 - val_recall: 0.9412 - val_precision: 0.9412\n",
            "Epoch 6638/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6995e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06638: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.6995e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9471 - val_recall: 0.9471 - val_precision: 0.9471\n",
            "Epoch 6639/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993    \n",
            "Epoch 06639: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 0.0033 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.3760 - val_accuracy: 0.9618 - val_recall: 0.9618 - val_precision: 0.9618\n",
            "Epoch 6640/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9963 - recall: 0.9963 - precision: 0.9963\n",
            "Epoch 06640: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 0.0364 - accuracy: 0.9963 - recall: 0.9963 - precision: 0.9963 - val_loss: 1.1055 - val_accuracy: 0.9059 - val_recall: 0.9059 - val_precision: 0.9059\n",
            "Epoch 6641/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06641: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0138 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 16.6278 - val_accuracy: 0.5294 - val_recall: 0.5294 - val_precision: 0.5294\n",
            "Epoch 6642/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 06642: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0201 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 10.0742 - val_accuracy: 0.5647 - val_recall: 0.5647 - val_precision: 0.5697\n",
            "Epoch 6643/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9985\n",
            "Epoch 06643: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0080 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9985 - val_loss: 5.5036 - val_accuracy: 0.7176 - val_recall: 0.7176 - val_precision: 0.7219\n",
            "Epoch 6644/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3005e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06644: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.3005e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.0299 - val_accuracy: 0.8412 - val_recall: 0.8412 - val_precision: 0.8437\n",
            "Epoch 6645/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1299e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06645: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.1299e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8853 - val_recall: 0.8853 - val_precision: 0.8853\n",
            "Epoch 6646/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5168e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06646: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5168e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.9206 - val_recall: 0.9206 - val_precision: 0.9288\n",
            "Epoch 6647/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2696e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06647: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2696e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.9471 - val_recall: 0.9441 - val_precision: 0.9525\n",
            "Epoch 6648/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0358e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06648: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.0358e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9618 - val_recall: 0.9588 - val_precision: 0.9617\n",
            "Epoch 6649/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1587e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06649: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.1587e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6650/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.3194e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06650: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.3194e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9676 - val_recall: 0.9647 - val_precision: 0.9676\n",
            "Epoch 6651/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1045e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06651: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 3.1045e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6652/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2030e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06652: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.2030e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6653/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5669e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06653: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5669e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6654/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8470e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06654: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.8470e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6655/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0436e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06655: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0436e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6656/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4074e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06656: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 2.4074e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6657/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2551e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06657: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2551e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6658/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7234e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06658: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.7234e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6659/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7995e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06659: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.7995e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6660/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8336e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06660: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8336e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6661/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4607e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06661: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 2.4607e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6662/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7969e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06662: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.7969e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6663/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7887e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06663: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.7887e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6664/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5217e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06664: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.5217e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6665/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2172e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06665: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.2172e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6666/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0733e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06666: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.0733e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6667/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8606e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06667: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 1.8606e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6668/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4501e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06668: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.4501e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6669/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6951e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06669: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.6951e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6670/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3316e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06670: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 8.3316e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6671/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.8993e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06671: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.8993e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6672/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4294e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06672: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.4294e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6673/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3321e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06673: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3321e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6674/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6807e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06674: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.6807e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6675/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6808e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06675: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.6808e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6676/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3944e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06676: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.3944e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6677/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9988e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06677: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.9988e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5574 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6678/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2657e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06678: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 1.2657e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6679/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5134e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06679: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.5134e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6680/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8709e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06680: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.8709e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6681/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9247e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06681: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.9247e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6682/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4906e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06682: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.4906e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5690 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6683/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3235e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06683: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 1.3235e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6684/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9749e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06684: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9749e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6685/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7018e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06685: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.7018e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6686/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5280e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06686: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5280e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5735 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6687/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8601e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06687: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.8601e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5738 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6688/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8067e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06688: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.8067e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6689/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1794e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06689: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.1794e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6690/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0076e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06690: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0076e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6691/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5388e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06691: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.5388e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6692/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1081e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06692: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1081e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6693/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.2056e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06693: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.2056e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6694/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5037e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06694: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.5037e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6695/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7948e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06695: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 5.7948e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5818 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6696/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7171e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06696: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.7171e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6697/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4105e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06697: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.4105e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6698/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4140e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06698: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.4140e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6699/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5512e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06699: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.5512e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6700/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3565e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06700: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.3565e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6701/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0758e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06701: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.0758e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6702/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0645e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06702: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 2.0645e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6703/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9154e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06703: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9154e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6704/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1068e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06705: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1068e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6706/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9846e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06706: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.9846e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6707/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3321e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06707: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3321e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6708/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5886e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06708: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.5886e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6709/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8274e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06709: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8274e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6710/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1343e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06710: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.1343e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6711/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6721e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06711: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.6721e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6712/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7420e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06712: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.7420e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6713/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1941e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06713: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.1941e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6714/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0225e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06714: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0225e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6715/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0640e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06715: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.0640e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6716/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5668e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06716: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.5668e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6717/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.9341e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06717: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.9341e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6718/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3015e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06718: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.3015e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6719/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0027e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06719: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0027e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6720/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5306e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06720: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5306e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6721/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0735e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06721: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0735e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6722/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1241e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06722: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 3.1241e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6723/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0577e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06723: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 1.0577e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6724/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8949e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06724: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 8.8949e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6725/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6623e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06725: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.6623e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6726/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.6918e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06726: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.6918e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6727/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1184e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06727: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 1.1184e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6728/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1473e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06728: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.1473e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6307 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6729/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8654e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06729: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.8654e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6297 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6730/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.9598e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06730: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.9598e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6731/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.0169e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06731: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.0169e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6732/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6234e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06732: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.6234e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6733/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1743e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06733: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.1743e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6734/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3640e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06734: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.3640e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6735/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6727e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06735: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.6727e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6736/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1866e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06736: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.1866e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6737/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4442e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06737: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4442e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6738/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5551e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06738: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.5551e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6739/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8308e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06739: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.8308e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6740/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0251e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06740: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0251e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6741/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3062e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06741: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.3062e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6742/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7729e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06742: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.7729e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6743/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9436e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06743: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 298ms/step - loss: 1.9436e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6077 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6744/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7424e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06744: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.7424e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6745/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5061e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06745: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 2.5061e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6746/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6710e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06746: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.6710e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6747/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7411e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06747: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.7411e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6748/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.0438e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06748: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.0438e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6749/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5398e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06749: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.5398e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6750/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6071e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06750: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.6071e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6751/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9114e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06751: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.9114e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6752/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6744e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06752: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.6744e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6753/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2273e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06753: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 3.2273e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6754/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1437e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06754: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 304ms/step - loss: 1.1437e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6755/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1499e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06758: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.1499e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6759/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0183e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06759: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.0183e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6760/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7470e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06760: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.7470e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6059 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6761/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6701e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06761: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.6701e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6042 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6762/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3653e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06762: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.3653e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6763/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9705e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06763: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.9705e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6764/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7007e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06764: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 5.7007e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6765/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.5382e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06765: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.5382e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6766/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0901e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06766: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.0901e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6767/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0616e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06767: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0616e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6768/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3097e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06768: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.3097e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6769/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.2715e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06769: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.2715e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6770/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3717e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06770: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.3717e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6771/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7368e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06771: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.7368e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6772/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1449e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06772: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.1449e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6773/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9261e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06773: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.9261e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6774/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1476e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06774: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1476e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6775/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3295e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06775: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.3295e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6776/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06776: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.7029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6777/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3793e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06777: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.3793e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6778/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9291e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06778: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9291e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6779/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2286e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06779: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.2286e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6780/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7793e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06780: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 5.7793e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6781/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4810e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06781: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.4810e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6782/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.3942e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06782: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.3942e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6783/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5704e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06783: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 5.5704e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6784/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.0029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06784: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.0029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6785/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6915e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06785: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.6915e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6786/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9606e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06786: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9606e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6787/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9349e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06787: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.9349e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6788/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5856e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06788: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.5856e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6789/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4711e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06789: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 4.4711e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6790/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5108e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06790: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.5108e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6791/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0085e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06791: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.0085e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6792/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4868e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06792: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4868e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6793/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2655e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06793: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 7.2655e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6794/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9976e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06794: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.9976e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6795/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9102e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06795: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.9102e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6796/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1534e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06796: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1534e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6797/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5136e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06797: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5136e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6798/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1251e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06798: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.1251e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6799/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4355e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06799: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.4355e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6800/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2875e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06800: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 304ms/step - loss: 2.2875e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6801/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.8395e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06801: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 9.8395e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.6563 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6802/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0377e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06802: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 4.0377e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6803/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8355e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06803: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.8355e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6804/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7042e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06804: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.7042e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6805/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3107e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06805: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 1.3107e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6806/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2125e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06806: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2125e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6807/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5549e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06807: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.5549e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6808/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4034e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06808: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.4034e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7658 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6809/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6994e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06809: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.6994e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6810/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3440e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06810: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.3440e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6811/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7130e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06811: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.7130e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6812/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.8059e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06812: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.8059e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6813/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1973e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06813: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1973e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7757 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6814/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3352e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06814: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.3352e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6815/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.9891e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06815: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 8.9891e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6816/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6763e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06816: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.6763e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6817/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.4056e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06817: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.4056e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6818/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06818: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.1859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6819/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5956e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06819: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.5956e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6820/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7122e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06820: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 3.7122e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7796 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6821/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7310e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06821: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.7310e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6822/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.4149e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06822: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.4149e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6823/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8641e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06823: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.8641e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6824/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4339e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06824: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.4339e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6825/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3344e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06825: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.3344e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6826/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.4939e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06826: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.4939e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6827/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2300e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06827: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.2300e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6828/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7202e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06828: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 6.7202e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6829/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1842e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06829: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1842e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6830/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0050e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06830: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0050e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6831/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3140e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06831: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 8.3140e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7734 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6832/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.0262e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06832: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.0262e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7743 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6833/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.5826e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06833: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 8.5826e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7751 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6834/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5592e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06834: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.5592e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6835/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6917e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06835: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 1.6917e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6836/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.8847e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06836: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.8847e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6837/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8811e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06837: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.8811e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7672 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6838/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4089e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06838: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.4089e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8314 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6839/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.0790e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06839: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.0790e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8876 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6840/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4487e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06840: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4487e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8869 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6841/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.2605e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06841: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 8.2605e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6842/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9043e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06842: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.9043e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6843/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1737e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06843: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.1737e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6844/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.1536e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06844: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.1536e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6845/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5914e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06845: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 2.5914e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6846/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8614e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06846: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 3.8614e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6847/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2795e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06847: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.2795e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6848/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0278e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06848: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0278e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6849/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978\n",
            "Epoch 06849: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0156 - accuracy: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 0.6610 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6850/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.7625e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06850: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.7625e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 4.2731 - val_accuracy: 0.7706 - val_recall: 0.7706 - val_precision: 0.7729\n",
            "Epoch 6851/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9441e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06851: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.9441e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 5.4831 - val_accuracy: 0.7265 - val_recall: 0.7235 - val_precision: 0.7257\n",
            "Epoch 6852/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06852: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 0.0036 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 7.9622 - val_accuracy: 0.6676 - val_recall: 0.6676 - val_precision: 0.6676\n",
            "Epoch 6853/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06853: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0013 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 17.5763 - val_accuracy: 0.5353 - val_recall: 0.5324 - val_precision: 0.5355\n",
            "Epoch 6854/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.6222e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06854: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.6222e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 13.0197 - val_accuracy: 0.5971 - val_recall: 0.5971 - val_precision: 0.5988\n",
            "Epoch 6855/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.2757e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06855: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.2757e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 8.0013 - val_accuracy: 0.6824 - val_recall: 0.6824 - val_precision: 0.6844\n",
            "Epoch 6856/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6731e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06856: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.6731e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 4.1876 - val_accuracy: 0.7559 - val_recall: 0.7559 - val_precision: 0.7604\n",
            "Epoch 6857/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9978 - recall: 0.9971 - precision: 0.9978\n",
            "Epoch 06857: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0392 - accuracy: 0.9978 - recall: 0.9971 - precision: 0.9978 - val_loss: 1.7575 - val_accuracy: 0.8941 - val_recall: 0.8941 - val_precision: 0.8941\n",
            "Epoch 6858/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9948 - recall: 0.9948 - precision: 0.9948\n",
            "Epoch 06858: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 0.0192 - accuracy: 0.9948 - recall: 0.9948 - precision: 0.9948 - val_loss: 5.5786 - val_accuracy: 0.8324 - val_recall: 0.8324 - val_precision: 0.8348\n",
            "Epoch 6859/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9963 - recall: 0.9963 - precision: 0.9963\n",
            "Epoch 06859: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0192 - accuracy: 0.9963 - recall: 0.9963 - precision: 0.9963 - val_loss: 14.7468 - val_accuracy: 0.6529 - val_recall: 0.6529 - val_precision: 0.6529\n",
            "Epoch 6860/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3543e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06860: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 7.3543e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 26.5338 - val_accuracy: 0.5088 - val_recall: 0.5088 - val_precision: 0.5088\n",
            "Epoch 6861/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06861: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0030 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 30.5988 - val_accuracy: 0.4706 - val_recall: 0.4706 - val_precision: 0.4706\n",
            "Epoch 6862/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06862: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0064 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 25.6131 - val_accuracy: 0.5118 - val_recall: 0.5118 - val_precision: 0.5118\n",
            "Epoch 6863/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985\n",
            "Epoch 06863: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0041 - accuracy: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 14.7300 - val_accuracy: 0.5941 - val_recall: 0.5941 - val_precision: 0.5941\n",
            "Epoch 6864/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9709e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06864: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.9709e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 8.9582 - val_accuracy: 0.6765 - val_recall: 0.6765 - val_precision: 0.6765\n",
            "Epoch 6865/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0063e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06865: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0063e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 5.3080 - val_accuracy: 0.7588 - val_recall: 0.7588 - val_precision: 0.7588\n",
            "Epoch 6866/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5780e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06866: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.5780e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.7010 - val_accuracy: 0.8559 - val_recall: 0.8559 - val_precision: 0.8559\n",
            "Epoch 6867/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3162e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06867: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.3162e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8583 - val_accuracy: 0.8853 - val_recall: 0.8853 - val_precision: 0.8853\n",
            "Epoch 6868/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9538e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06868: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.9538e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4359 - val_accuracy: 0.9088 - val_recall: 0.9088 - val_precision: 0.9088\n",
            "Epoch 6869/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.3303e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06869: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 5.3303e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.8688 - val_accuracy: 0.9294 - val_recall: 0.9294 - val_precision: 0.9294\n",
            "Epoch 6870/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06870: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0014 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.9089 - val_accuracy: 0.9265 - val_recall: 0.9265 - val_precision: 0.9265\n",
            "Epoch 6871/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0702e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06871: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.0702e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9274 - val_accuracy: 0.9265 - val_recall: 0.9265 - val_precision: 0.9265\n",
            "Epoch 6872/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06872: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 0.0015 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.7269 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6873/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1783e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06873: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1783e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6874/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.3164e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06874: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.3164e-04 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.7610 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6875/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9167e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06875: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.9167e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8779 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6876/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7739e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06876: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.7739e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6877/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6935e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06877: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.6935e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
            "Epoch 6878/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2252e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06878: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.2252e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.9588 - val_recall: 0.9588 - val_precision: 0.9588\n",
            "Epoch 6879/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.5854e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06879: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 5.5854e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.9647 - val_recall: 0.9647 - val_precision: 0.9647\n",
            "Epoch 6880/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9014e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06880: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.9014e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6881/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7269e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06881: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.7269e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5949 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6882/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9284e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06882: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 6.9284e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9706 - val_recall: 0.9676 - val_precision: 0.9705\n",
            "Epoch 6883/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9221e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06883: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.9221e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9735\n",
            "Epoch 6884/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.1029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06884: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.1029e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6885/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8908e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06885: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.8908e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6886/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6725e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06886: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 3.6725e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6887/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.4339e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06887: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 8.4339e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6888/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0629e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06888: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 2.0629e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6889/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0767e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06889: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.0767e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6890/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2274e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06890: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.2274e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6891/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2791e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06891: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 1.2791e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6892/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0405e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06892: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.0405e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6893/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8593e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06893: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.8593e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6894/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8350e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06894: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 7.8350e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6895/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5810e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06895: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 2.5810e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6896/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9461e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06896: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.9461e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6897/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.3648e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06897: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.3648e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6898/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.7402e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06898: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 7.7402e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6899/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5746e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06902: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.5746e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6903/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6983e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06903: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.6983e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6904/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.1162e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06904: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 9.1162e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6905/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5360e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06905: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5360e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6906/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0535e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06906: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.0535e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6907/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4524e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06907: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.4524e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6908/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.1545e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06908: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 4.1545e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6909/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1026e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06909: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.1026e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6910/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993\n",
            "Epoch 06910: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 0.0026 - accuracy: 0.9993 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.3766 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6911/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5570e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06911: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.5570e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6912/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.6715e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06912: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.6715e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6913/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0626e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06913: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0626e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6914/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0824e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06914: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0824e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6915/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.7355e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06915: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.7355e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6916/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5884e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06916: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 267ms/step - loss: 3.5884e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6917/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5805e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06917: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 4.5805e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9676 - val_recall: 0.9676 - val_precision: 0.9676\n",
            "Epoch 6918/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.7211e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06918: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 8.7211e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6919/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7961e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06919: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 6.7961e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6920/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0360e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06920: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 5.0360e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6921/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.0503e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06921: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.0503e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6922/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0341e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06922: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 4.0341e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6923/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.7917e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06923: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.7917e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6924/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.8922e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06924: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.8922e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6925/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.1395e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06925: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.1395e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6926/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.3572e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06926: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.3572e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6927/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2882e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06927: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.2882e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6928/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0287e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06928: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.0287e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6929/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2676e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06929: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.2676e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6930/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9292e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06930: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.9292e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6931/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9564e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06931: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.9564e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6932/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5063e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06932: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5063e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6933/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.9618e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06933: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 3.9618e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6934/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2219e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06934: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 1.2219e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6935/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0494e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06935: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0494e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6936/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5834e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06936: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5834e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6937/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.1121e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06937: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 8.1121e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6938/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1390e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06938: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.1390e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6939/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1976e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06939: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1976e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6940/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3542e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06940: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.3542e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6941/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2400e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06941: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.2400e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6942/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1530e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06942: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1530e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6943/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4069e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06943: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 2.4069e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6944/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1271e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06944: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.1271e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6945/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9338e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06945: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 1.9338e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6946/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.3859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06946: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.3859e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6947/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.4016e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06947: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.4016e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6948/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3283e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06948: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.3283e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6949/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7692e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06949: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.7692e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6950/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1004e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06950: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.1004e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6951/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.5173e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06951: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.5173e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6952/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0612e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06952: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.0612e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9706 - val_recall: 0.9706 - val_precision: 0.9706\n",
            "Epoch 6953/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8953e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06953: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 2.8953e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6954/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.5918e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06954: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 7.5918e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6955/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1606e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06955: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1606e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6956/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4692e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06956: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4692e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6957/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.2160e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06957: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 3.2160e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6958/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7541e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06958: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.7541e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6959/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0462e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06959: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.0462e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6960/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.8515e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06960: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 302ms/step - loss: 4.8515e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6961/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5608e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06961: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.5608e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6962/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.6074e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06962: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.6074e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6963/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4058e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06963: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.4058e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6964/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.6814e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06964: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 3.6814e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6965/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4802e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06965: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4802e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6966/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.0497e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06966: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.0497e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6967/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2606e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06967: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 1.2606e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6968/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.6500e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06968: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 6.6500e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6969/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.7744e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06969: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 6.7744e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6970/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8916e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06970: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.8916e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6971/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4245e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06971: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.4245e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6972/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.5905e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06972: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 2.5905e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6973/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1144e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06973: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 303ms/step - loss: 2.1144e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6974/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7861e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06974: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 1.7861e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6975/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 9.1272e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06975: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 9.1272e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6976/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5370e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06976: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 273ms/step - loss: 4.5370e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6977/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.5975e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06977: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 4.5975e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6978/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.1543e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06978: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.1543e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6979/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.2802e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06979: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 7.2802e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6980/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.0161e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06980: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.0161e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6981/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1347e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06981: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.1347e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6982/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4266e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06982: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 1.4266e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6983/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.4950e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06983: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 3.4950e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6984/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.7086e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06984: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.7086e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6985/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 8.2932e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06985: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 8.2932e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6986/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.8057e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06986: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.8057e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6987/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.9399e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06987: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.9399e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6988/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9084e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06988: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.9084e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6989/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1139e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06989: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.1139e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6990/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.5041e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06990: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 1.5041e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6991/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9268e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06991: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.9268e-06 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6992/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9804e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06992: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 299ms/step - loss: 2.9804e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6993/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 7.8622e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06993: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 7.8622e-08 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6994/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.9568e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06994: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 2.9568e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6995/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 6.9223e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06995: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 269ms/step - loss: 6.9223e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6996/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6046e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06996: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 2.6046e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6997/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 5.1286e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06997: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 5.1286e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6998/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 3.5997e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06998: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 3.5997e-07 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 6999/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6682e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 06999: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 301ms/step - loss: 2.6682e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n",
            "Epoch 7000/7000\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0846e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
            "Epoch 07000: val_loss did not improve from 0.07137\n",
            "11/11 [==============================] - 3s 270ms/step - loss: 1.0846e-05 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9735 - val_recall: 0.9735 - val_precision: 0.9735\n"
          ]
        }
      ],
      "source": [
        "import keras.optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam()\n",
        "transfer_learning_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy',keras.metrics.Recall(), keras.metrics.Precision()])\n",
        "#fitting the new model\n",
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath = 'transfer_learning.hdf5', verbose = 1, save_best_only = True)\n",
        "\n",
        "# running \n",
        "transfer_learning_cnn = transfer_learning_model.fit(X_train,y_train,\n",
        "        batch_size = 128,\n",
        "        epochs=7000,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks = [checkpointer],\n",
        "        verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spO_WcaxvhTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5694e92-7c9b-439e-afcd-8be6b29f91d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 77ms/step - loss: 0.3522 - accuracy: 0.9735 - recall: 0.9735 - precision: 0.9735\n",
            "Test accuracy: 0.9735293984413147\n"
          ]
        }
      ],
      "source": [
        "#score of the new model built using transfer learning\n",
        "score = transfer_learning_model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_2p8rNhvwGH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOWb5vmLvkxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "eab7b966-00eb-49d9-ffb1-3e3818c1fbf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f59881724d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "y_pred = transfer_learning_model.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=-1)\n",
        "t_true=np.argmax(y_test,axis=-1)\n",
        "Improved=confusion_matrix(t_true, y_pred,labels=output_lebel)\n",
        "sns.heatmap(Improved,annot=True,cmap=\"YlGnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmBjdkLqvoTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "6a27a300-bae6-4d92-c21e-dfcbeffcb535"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plotting curves for the transfer learning model\n",
        "\n",
        "plt.figure(1, figsize = (10, 10))  \n",
        "plt.subplot(211)  \n",
        "plt.plot(transfer_learning_cnn.history['accuracy'])  \n",
        "plt.plot(transfer_learning_cnn.history['val_accuracy'])  \n",
        "plt.title('Model Accuracy')  \n",
        "plt.ylabel('Accuracy')  \n",
        "plt.xlabel('Epoch')  \n",
        "plt.legend(['train', 'validation'], loc='upper left')   \n",
        "\n",
        "# plotting model loss \n",
        "plt.subplot(212)  \n",
        "plt.plot(transfer_learning_cnn.history['loss'])  \n",
        "plt.plot(transfer_learning_cnn.history['val_loss'])  \n",
        "plt.title('Model Loss')  \n",
        "plt.ylabel('Loss')  \n",
        "plt.xlabel('Epoch')  \n",
        "plt.legend(['train', 'validation'], loc='upper left')  \n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Improved .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDDzRnVMs9bHNGz5+yctrS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}